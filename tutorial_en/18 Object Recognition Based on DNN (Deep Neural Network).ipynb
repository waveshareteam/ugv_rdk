{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94c9f371-d7b4-47c0-8d44-783e4bb3eb5e",
   "metadata": {},
   "source": [
    "# Object Recognition Based on DNN (Deep Neural Network)\n",
    "\n",
    "This section introduces how to implement common object recognition using DNN (Deep Neural Network) + OpenCV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca053161-5d7d-416d-bf90-67268d5de85c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Preparation\n",
    "\n",
    "Since the product automatically runs the main program at startup, which occupies the camera resource, this tutorial cannot be used in such situations. You need to terminate the main program or disable its automatic startup before restarting the robot.\n",
    "\n",
    "It's worth noting that because the robot's main program uses multi-threading and is configured to run automatically at startup through crontab, the usual method sudo killall python typically doesn't work. Therefore, we'll introduce the method of disabling the automatic startup of the main program here.\n",
    "\n",
    "### Terminate the Main Program\n",
    "\n",
    "1. Click the \"+\" icon next to the tab for this page to open a new tab called \"Launcher.\"\n",
    "2. Click on \"Terminal\" under \"Other\" to open a terminal window.\n",
    "3. Type bash into the terminal window and press Enter.\n",
    "4. Now you can use the Bash Shell to control the robot.\n",
    "5. Enter the command: `sudo killall -9 python`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462bab71-b036-45dd-aa41-7933473fed22",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "The following code block can be run directly:\n",
    "\n",
    "1. Select the code block below.\n",
    "2. Press Shift + Enter to run the code block.\n",
    "3. Watch the real-time video window.\n",
    "4. Press `STOP` to close the real-time video and release the camera resources.\n",
    "\n",
    "### If you cannot see the real-time camera feed when running:\n",
    "\n",
    "- Click on Kernel -> Shut down all kernels above.\n",
    "- Close the current section tab and open it again.\n",
    "- Click `STOP` to release the camera resources, then run the code block again.\n",
    "- Reboot the device.\n",
    "\n",
    "### Features of This Section\n",
    "\n",
    "The `deploy.prototxt` file and `mobilenet_iter_73000.caffemodel` file are in the same path as this .ipynb file.\n",
    "\n",
    "When the code blocks run successfully, you can point the camera at common objects such as: \"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\".\n",
    "\n",
    "The program will annotate the objects it recognizes in the image and label them with their names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bf629f-42fb-4fd7-b17b-adb4e8365685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  # Import the OpenCV library for image processing\n",
    "import numpy as np  # Library for mathematical calculations\n",
    "from IPython.display import display, Image  # Library for displaying images in Jupyter Notebook\n",
    "import ipywidgets as widgets  # Library for creating interactive widgets like buttons\n",
    "import threading  # Library for creating new threads for asynchronous task execution\n",
    "\n",
    "# Pre-defined class names based on the Caffe model\n",
    "class_names = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
    "               \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "               \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n",
    "               \"sofa\", \"train\", \"tvmonitor\"]\n",
    "\n",
    "# Load the Caffe model\n",
    "net = cv2.dnn.readNetFromCaffe('deploy.prototxt', 'mobilenet_iter_73000.caffemodel')\n",
    "\n",
    "# Create a \"Stop\" button for users to stop the video stream by clicking it\n",
    "# ================\n",
    "stopButton = widgets.ToggleButton(\n",
    "    value=False,\n",
    "    description='Stop',\n",
    "    disabled=False,\n",
    "    button_style='danger', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Description',\n",
    "    icon='square' # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "\n",
    "\n",
    "# Define the display function to process video frames and perform object detection\n",
    "# ================\n",
    "def view(button):\n",
    "    camera = cv2.VideoCapture(-1) \n",
    "    camera.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "    camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "    \n",
    "    display_handle=display(None, display_id=True)  # Create a display handle for updating displayed images\n",
    "    i = 0\n",
    "    \n",
    "    avg = None\n",
    "    \n",
    "    while True:\n",
    "        # frame = picam2.capture_array() # Capture a frame from the camera\n",
    "        _, frame = camera.read()\n",
    "        # frame = cv2.flip(frame, 1) # if your camera reverses your image\n",
    "\n",
    "        img = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)  # Convert the image from RGB to BGR because OpenCV uses BGR by default\n",
    "        (h, w) = img.shape[:2]  # Get the height and width of the image\n",
    "        # Generate the input blob for the network\n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)), 0.007843, (300, 300), 127.5)\n",
    "        net.setInput(blob)  # Set the blob as the input to the network\n",
    "        detections = net.forward()  # Perform forward pass to get the detection results\n",
    "\n",
    "        # Loop over the detected objects\n",
    "        for i in range(0, detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]  # Get the confidence of the detected object\n",
    "            if confidence > 0.2:  # If the confidence is above the threshold, process the detected object\n",
    "                idx = int(detections[0, 0, i, 1])  # Get the class index\n",
    "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])  # Get the bounding box of the object\n",
    "                (startX, startY, endX, endY) = box.astype(\"int\")  # Convert the bounding box to integers\n",
    "\n",
    "                # Annotate the object and confidence on the image\n",
    "                label = \"{}: {:.2f}%\".format(class_names[idx], confidence * 100)\n",
    "                cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "                y = startY - 15 if startY - 15 > 15 else startY + 15\n",
    "                cv2.putText(frame, label, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        \n",
    "        _, frame = cv2.imencode('.jpeg', frame)  # Encode the frame as JPEG format\n",
    "        display_handle.update(Image(data=frame.tobytes()))  # Update the displayed image\n",
    "        if stopButton.value==True:  # Check if the \"Stop\" button is pressed\n",
    "            # picam2.close()  # If yes, close the camera\n",
    "            cv2.release() # If yes, close the camera\n",
    "            display_handle.update(None)  # Clear the displayed content\n",
    "\n",
    "            \n",
    "# Display the \"Stop\" button and start the display function's thread\n",
    "# ================\n",
    "display(stopButton)\n",
    "thread = threading.Thread(target=view, args=(stopButton,))\n",
    "thread.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
