{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "019fbb00-544a-4870-aab5-5e1369e3bac6",
   "metadata": {},
   "source": [
    "# Line Following Autonomous Driving with OpenCV\n",
    "\n",
    "In this tutorial, we'll use basic functionalities of OpenCV to detect yellow lines (default color) in the image and control the direction of the chassis based on the position of these lines. Please note that in this example, the chassis won't move. Instead, we'll only showcase the algorithms using OpenCV on the image. For safety reasons, we won't integrate motion control in this tutorial, as it's heavily influenced by external factors. Users should fully understand the code's functionality before adding corresponding motion control features.\r\n",
    "\r\n",
    "If you want to control the robot's movement through this example, please refer to the \"Python Chassis Motion Control\" section to add the relevant motion control functions (our open-source example is located in robot_ctrl.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdb3f7e-09a4-4e54-87dd-b59cb1fd3deb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Preparation\n",
    "\n",
    "Since the product automatically runs the main program at startup, which occupies the camera resource, this tutorial cannot be used in such situations. You need to terminate the main program or disable its automatic startup before restarting the robot.\n",
    "\n",
    "It's worth noting that because the robot's main program uses multi-threading and is configured to run automatically at startup through crontab, the usual method sudo killall python typically doesn't work. Therefore, we'll introduce the method of disabling the automatic startup of the main program here.\n",
    "\n",
    "### Terminate the Main Program\n",
    "\n",
    "1. Click the \"+\" icon next to the tab for this page to open a new tab called \"Launcher.\"\n",
    "2. Click on \"Terminal\" under \"Other\" to open a terminal window.\n",
    "3. Type bash into the terminal window and press Enter.\n",
    "4. Now you can use the Bash Shell to control the robot.\n",
    "5. Enter the command: `sudo killall -9 python`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f373291f-9bf0-4182-be22-7068a3740ed5",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "The following code block can be run directly:\n",
    "\n",
    "1. Select the code block below.\n",
    "2. Press Shift + Enter to run the code block.\n",
    "3. Watch the real-time video window.\n",
    "4. Press `STOP` to close the real-time video and release the camera resources.\n",
    "\n",
    "### If you cannot see the real-time camera feed when running:\n",
    "\n",
    "- Click on Kernel -> Shut down all kernels above.\n",
    "- Close the current section tab and open it again.\n",
    "- Click `STOP` to release the camera resources, then run the code block again.\n",
    "- Reboot the device.\n",
    "\n",
    "### Features of this Section\n",
    "\n",
    "After running the following code block, you can place a yellow tape in front of the camera and observe if there are contours of the yellow tape in the black screen. Try to detect the yellow tape using two target detection lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec0096c-d92d-49fa-85a3-aeba8f844f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  # Import the OpenCV library for image processing\n",
    "import imutils, math  # Auxiliary libraries for image processing and mathematical operations\n",
    "import numpy as np\n",
    "from IPython.display import display, Image  # Library for displaying images in Jupyter Notebook\n",
    "import ipywidgets as widgets  # Library for creating interactive widgets such as buttons\n",
    "import threading  # Library for creating new threads to execute tasks asynchronously\n",
    "\n",
    "# Stop button\n",
    "# ================\n",
    "stopButton = widgets.ToggleButton(\n",
    "    value=False,\n",
    "    description='STOP',\n",
    "    disabled=False,\n",
    "    button_style='danger',  # Button style: 'success', 'info', 'warning', 'danger', or ''\n",
    "    tooltip='Description',\n",
    "    icon='square'  # FontAwesome icon name (without the `fa-` prefix)\n",
    ")\n",
    "\n",
    "# Line Tracking Autonomous Driving\n",
    "\n",
    "# Upper detection line, 0.6 represents position, with higher values indicating farther from the bottom\n",
    "sampling_line_1 = 0.6\n",
    "\n",
    "# Lower detection line, the value needs to be greater than sampling_line_1 and less than 1\n",
    "sampling_line_2 = 0.9\n",
    "\n",
    "# Impact of line slope on turning\n",
    "slope_impact = 1.5\n",
    "\n",
    "# Impact of line position detected by the lower detection line on turning\n",
    "base_impact = 0.005\n",
    "\n",
    "# Impact of current speed on turning\n",
    "speed_impact = 0.5\n",
    "\n",
    "# Line tracking speed\n",
    "line_track_speed = 0.3\n",
    "\n",
    "# Impact of slope on line tracking speed\n",
    "slope_on_speed = 0.1\n",
    "\n",
    "# Target line color, in HSV color space\n",
    "line_lower = np.array([25, 150, 70])\n",
    "line_upper = np.array([42, 255, 255])\n",
    "\n",
    "def view(button):\n",
    "    camera = cv2.VideoCapture(-1) \n",
    "    camera.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "    camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "    \n",
    "    display_handle=display(None, display_id=True)\n",
    "    \n",
    "    while True:\n",
    "        # img = picam2.capture_array()\n",
    "        _, img = camera.read()\n",
    "        # frame = cv2.flip(frame, 1) # if your camera reverses your image\n",
    "\n",
    "        # frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        height, width = img.shape[:2]\n",
    "        center_x, center_y = width // 2, height // 2\n",
    "        # Image preprocessing, including color space conversion, Gaussian blur, color range filtering, etc.\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        line_mask = cv2.inRange(hsv, line_lower, line_upper)  # Filter out target lines based on color range\n",
    "        line_mask = cv2.erode(line_mask, None, iterations=1)  # Erosion operation to remove noise\n",
    "        line_mask = cv2.dilate(line_mask, None, iterations=1)  # Dilation operation to enhance target lines\n",
    "\n",
    "        # Detect target lines based on the positions of the upper and lower sampling lines, and calculate steering and speed control signals based on the detection results\n",
    "        sampling_h1 = int(height * sampling_line_1)\n",
    "        sampling_h2 = int(height * sampling_line_2)\n",
    "        \n",
    "        get_sampling_1 = line_mask[sampling_h1]\n",
    "        get_sampling_2 = line_mask[sampling_h2]\n",
    "\n",
    "        # Calculate the width of the target line at the upper and lower sampling lines\n",
    "        sampling_width_1 = np.sum(get_sampling_1 == 255)\n",
    "        sampling_width_2 = np.sum(get_sampling_2 == 255)\n",
    "\n",
    "        if sampling_width_1:\n",
    "            sam_1 = True\n",
    "        else:\n",
    "            sam_1 = False\n",
    "        if sampling_width_2:\n",
    "            sam_2 = True\n",
    "        else:\n",
    "            sam_2 = False\n",
    "\n",
    "        # Get the edge indices of the target line at the upper and lower sampling lines\n",
    "        line_index_1 = np.where(get_sampling_1 == 255)\n",
    "        line_index_2 = np.where(get_sampling_2 == 255)\n",
    "\n",
    "        # If the target line is detected at the upper sampling line, calculate the center position of the target line\n",
    "        if sam_1:\n",
    "            sampling_1_left  = line_index_1[0][0]  # The leftmost index of the target line at the upper sampling line\n",
    "            sampling_1_right = line_index_1[0][sampling_width_1 - 1]  # The rightmost index of the target line at the upper sampling line\n",
    "            sampling_1_center= int((sampling_1_left + sampling_1_right) / 2)  # The index of the center of the target line at the upper sampling line\n",
    "        # If the target line is detected at the lower sampling line, calculate the center position of the target line\n",
    "        if sam_2:\n",
    "            sampling_2_left  = line_index_2[0][0]\n",
    "            sampling_2_right = line_index_2[0][sampling_width_2 - 1]\n",
    "            sampling_2_center= int((sampling_2_left + sampling_2_right) / 2)\n",
    "\n",
    "        # Initialize steering and speed control signals\n",
    "        line_slope = 0\n",
    "        input_speed = 0\n",
    "        input_turning = 0\n",
    "        \n",
    "        # If the target line is detected at both sampling lines, calculate the line slope and speed and steering control signals based on the slope and position of the target line\n",
    "        if sam_1 and sam_2:\n",
    "            line_slope = (sampling_1_center - sampling_2_center) / abs(sampling_h1 - sampling_h2) # Calculate the line slope\n",
    "            impact_by_slope = slope_on_speed * abs(line_slope) # Calculate the impact on speed based on the slope\n",
    "            input_speed = line_track_speed - impact_by_slope # Calculate the speed control signal\n",
    "            input_turning = -(line_slope * slope_impact + (sampling_2_center - center_x) * base_impact) # Calculate the steering control signal\n",
    "        elif not sam_1 and sam_2: # If only the target line is detected at the lower sampling line\n",
    "            input_speed = 0 # Set speed to 0\n",
    "            input_turning = (sampling_2_center - center_x) * base_impact # Calculate the steering control signal\n",
    "        elif sam_1 and not sam_2: # If only the target line is detected at the upper sampling line\n",
    "            input_speed = (line_track_speed / 3) # Slow down speed\n",
    "            input_turning = 0 # No steering\n",
    "        else: # If no target line is detected at both sampling lines\n",
    "            input_speed = - (line_track_speed / 3) # Reverse\n",
    "            input_turning = 0 # No steering\n",
    "\n",
    "        # base.base_json_ctrl({\"T\":13,\"X\":input_speed,\"Z\":input_turning})\n",
    "\n",
    "        cv2.putText(line_mask, f'X: {input_speed:.2f}, Z: {input_turning:.2f}', (center_x+50, center_y+0), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        # Visualization operations, including drawing lines at sampling line positions, marking sampling results, and displaying steering and speed control signals\n",
    "        cv2.line(line_mask, (0, sampling_h1), (img.shape[1], sampling_h1), (255, 0, 0), 2)\n",
    "        cv2.line(line_mask, (0, sampling_h2), (img.shape[1], sampling_h2), (255, 0, 0), 2)\n",
    "\n",
    "        if sam_1:\n",
    "            # Draw green marker lines at both ends of the target line at the upper sampling line\n",
    "            cv2.line(line_mask, (sampling_1_left, sampling_h1+20), (sampling_1_left, sampling_h1-20), (0, 255, 0), 2)\n",
    "            cv2.line(line_mask, (sampling_1_right, sampling_h1+20), (sampling_1_right, sampling_h1-20), (0, 255, 0), 2)\n",
    "        if sam_2:\n",
    "            # Draw green marker lines at both ends of the target line at the lower sampling line\n",
    "            cv2.line(line_mask, (sampling_2_left, sampling_h2+20), (sampling_2_left, sampling_h2-20), (0, 255, 0), 2)\n",
    "            cv2.line(line_mask, (sampling_2_right, sampling_h2+20), (sampling_2_right, sampling_h2-20), (0, 255, 0), 2)\n",
    "        if sam_1 and sam_2:\n",
    "            # If the target line is detected at both upper and lower sampling lines, draw a red line from the center of the upper sampling line to the center of the lower sampling line\n",
    "            cv2.line(line_mask, (sampling_1_center, sampling_h1), (sampling_2_center, sampling_h2), (255, 0, 0), 2)\n",
    "        \n",
    "        _, frame = cv2.imencode('.jpeg', line_mask)\n",
    "        display_handle.update(Image(data=frame.tobytes()))\n",
    "        if stopButton.value==True:\n",
    "            # picam2.close() # If yes, close the camera\n",
    "            cv2.release() # If yes, close the camera\n",
    "            display_handle.update(None)\n",
    "\n",
    "\n",
    "# Display the \"STOP\" button and start a thread to execute the display function\n",
    "# ================\n",
    "display(stopButton)\n",
    "thread = threading.Thread(target=view, args=(stopButton,))\n",
    "thread.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
